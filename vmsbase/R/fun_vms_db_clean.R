

#' Neural Network Plotting - Internal Function
#'  
#' 
#' The \code{plotNet} is the internal function that implements the
#'  Neural Network Plotting routine.
#' 
#' This function,  with a Neural Network, a Prediction Index and a Confusion Matrix, generated by \code{\link{gui_vms_met_pred}},
#'  plots the graphical overall result of the neural network prediction.
#'   
#' 
#' @return This function does not return a value. 
#' 
#' @param net The Neural Network
#' @param Dg The Prediction Index
#' @param ConfMat The Confusion Matrix
#' 
#' @usage plotNet(net, Dg, ConfMat)
#'
#'
#'@references free text reference Pointers to the literature related to this object.
#'@seealso \code{\link{gui_vms_met_pred}}
#' @name plotNet

plotNet <- function(net,Dg,ConfMat){
  TrErr <- net$Merror[,1]
  VaErr <- net$Merror[,2]
  
  min <- min(ConfMat)
  max <- max(ConfMat)
  yLabels <- rownames(ConfMat)
  xLabels <- colnames(ConfMat)
  title <-c("Confusion Matrix")
  # Red and green range from 0 to 1 while Blue ranges from 1 to 0
  ColorRamp <- rgb( seq(0,1,length=256),  # Red
                    seq(0,1,length=256),  # Green
                    seq(1,0,length=256))  # Blue
  ColorLevels <- seq(min, max, length=length(ColorRamp))
  # Reverse Y axis
  reverse <- nrow(ConfMat) : 1
  yLabels <- yLabels[reverse]
  ConfMat <- ConfMat[reverse,]
  
  
  #Define layout
  layout(matrix(data=c(1,2,1,3), nrow=2, ncol=2), widths=c(4,1,4,1), heights=c(4,4))
  #Plot Error
  par(las=2)
  plot(TrErr, type="l",
       ylim=c(0,1.1*max(net$Merror)),
       lwd=2,col=2,
       xlab="Iteration",
       ylab="Mean Error")
  lines(VaErr,lwd=2,col=4)
  legend(0,#0.8*length(TrErr), 
         y = 0.6*max(net$Merror), 
         legend = c("Training","Validation"), 
         fill = c(2,4), col = c(2,4),cex=0.8)
  #Plot Conf Mat
  # Data Map
  par(mar = c(7,11,2,4),las=2)
  image(1:length(xLabels), 1:length(yLabels), t(ConfMat), col=ColorRamp, xlab="",
        ylab="", axes=FALSE, zlim=c(min,max))
  if( !is.null(title) ){
    title(main=title)
  }
  axis(BELOW<-1, at=1:length(xLabels), labels=xLabels, cex.axis=0.7)
  axis(LEFT <-2, at=1:length(yLabels), labels=yLabels, las= HORIZONTAL<-1,
       cex.axis=0.7)
  
  # Color Scale
  par(mar = c(3,2.5,2.5,2))
  image(1, ColorLevels,
        matrix(data=ColorLevels, ncol=length(ColorLevels),nrow=1),
        col=ColorRamp,
        xlab="",ylab="",
        xaxt="n")
}

StandardizeByCol <- function(xdata){
  ncolx <- ncol(xdata)
  for(ij in 1:ncolx){
    minx <- min(xdata[,ij],na.rm=TRUE)
    maxx <- max(xdata[,ij],na.rm=TRUE)
    xdata[,ij] <- (xdata[,ij] - minx)/(maxx-minx)
  } 
  return(xdata)
}


#' Shape File Data Joining - Internal Function
#'  
#' 
#' The \code{Join2shp} is the internal function that implements the
#'  Shape File Data Joining routine.
#' 
#' This function,  with a Grid Shape File, an Effort Count Vector and a File Destination Directory,
#'  (see \code{\link{gui_out_grid}}),
#'  creates a new Grid Shape File annotated with the Effort Count Vector.
#'   
#' 
#' @return This function does not return a value. 
#' 
#' @param shpfile The Original Grid Shape File
#' @param datavector The Effort Count Vector
#' @param dirdest The File Destination Directory
#' 
#' @usage Join2shp(shpfile, datavector, dirdest)
#'
#'
#'@references free text reference Pointers to the literature related to this object.
#'@seealso \code{\link{gui_out_grid}}
#' @name Join2shp

Join2shp <- function(shpfile, datavector, dirdest)
{
  sys_typ <- ifelse(.Platform$OS.type == "windows", "\\\\" , "/")
  diror <- paste(unlist(strsplit(shpfile, sys_typ))[1:length(unlist(strsplit(shpfile, sys_typ)))-1], collapse = sys_typ)
  if(diror == dirdest)
  {
    dirdest <- paste(dirdest, sys_typ, "grid", sep = "")
    dir.create(dirdest)
  }
  file_anm <- unlist(strsplit(unlist(strsplit(shpfile, sys_typ))[length(unlist(strsplit(shpfile, sys_typ)))], "[.]"))[1]
  
  otherfiles <- dir(diror)
  otherfiles <- otherfiles[grep(file_anm, otherfiles)]
  
  new_name <- ginput("Enter a name for\n the new shp file", title = "Shp File Name")
  
  for(iff in 1:length(otherfiles))
  {
    file.copy(from = paste(diror, sys_typ, otherfiles[iff], sep = "", collapse = ""), 
              to = paste(dirdest, sys_typ, new_name, ".", unlist(strsplit(otherfiles[iff], "[.]"))[length(unlist(strsplit(otherfiles[iff], "[.]")))], sep = "", collapse = ""))      
  }    
  dbfdata <- read.dbf(paste(diror, sys_typ,file_anm, ".dbf", sep = ""), as.is = TRUE)
  
  dbfdata$Count <- datavector
  
  write.dbf(dbfdata, paste(dirdest, sys_typ, new_name, ".dbf", sep = "", collapse = ""))
}

# Original spline basis
H0 = function(x) return(2*x^3-3*x^2+1)
H1 = function(x) return(-2*x^3+3*x^2)
H2 = function(x) return(x^3-2*x^2+x)
H3 = function(x) return(x^3-x^2)
# Derivatives
dH0 = function(x) return(6*x^2 - 6*x)
dH1 = function(x) return(-6*x^2 + 6*x)
dH2 = function(x) return(3*x^2 - 4*x + 1)
dH3 = function(x) return(3*x^2 - 2*x)

# by Josh O'Brien on http://stackoverflow.com/questions/9186496/determining-utm-zone-to-convert-from-longitude-latitude
long2UTM <- function(long) {
  (floor((long + 180)/6) %% 60) + 1
}

# # Original spline basis
# H0 = function(x) return((2*x^3)-(3*x^2)+1)
# H1 = function(x) return(-(2*x^3)+(3*x^2)
# H2 = function(x) return((x^3)-(2*x^2)+x)
# H3 = function(x) return((x^3)-(x^2))
# 
# # Derivatives
# dH0 = function(x) return((6*x^2) - (6*x))
# dH1 = function(x) return(-(6*x^2) + (6*x))
# dH2 = function(x) return((3*x^2) - (4*x) + 1)
# dH3 = function(x) return((3*x^2) - (2*x))


recu_dep <- function(xmin, xmax, ymin, ymax, resolut = 2, the_db = "")
{
  if(the_db != "")
  {
    
    co_ce <- fn$sqldf("select count(*) from intrp where LON > `xmin` and LON < `xmax` and LAT > `ymin` and LAT < `ymax`", dbname = the_db)
    
    if(co_ce[1,1] == 0)
    {
      cat("\n   -     Skipped block: x(", xmin, ",",xmax, ")*y(",ymin,",",ymax,")     -\n", sep = "")
    }else{
      xrange = c(xmin, xmax)
      yrange = c(ymin, ymax)
      # 	map("worldHires", xlim = xrange, ylim = yrange, bg = "darkorange2", col = "black", fill = T)
      # 	map.axes()
      l_x <- xmax - xmin
      l_y <- ymax - ymin
      if(l_x <= 0.25 | l_y <= 0.25)
      {
        cat("\n   -     New valid block: x(", xmin, ",",xmax, ")*y(",ymin,",",ymax,")     -\n", sep = "")
        deppoi <- fn$sqldf("select ROWID, * from intrp where LON > `xmin` and LON < `xmax` and LAT > `ymin` and LAT < `ymax`", dbname = the_db)
        
        cat("\n   -     Analyzing ", nrow(deppoi), " points     -\n\n", sep = "")
        
        bat_blo <- getNOAA.bathy(xmin-0.1,
                                 xmax+0.1,
                                 ymin-0.1,
                                 ymax+0.1, resolution = resolut)
        plot(bat_blo, image = T)
        points(deppoi[,"LON"], deppoi[,"LAT"], pch = 20, col = "firebrick")
        
        xlon <- rep(as.numeric(rownames(bat_blo)),length(as.numeric(colnames(bat_blo))))
        ylat <- rep(as.numeric(colnames(bat_blo)),each=length(as.numeric(rownames(bat_blo))))
        zdep <- as.numeric(bat_blo)
        cat("\n   -     Calculating Spline...     -", sep = "")
        SplineD <- o_Tps(cbind(xlon, ylat), zdep, lon.lat=TRUE)
        rm(bat_blo, zdep, xlon, ylat)
        cat("\n   -     Predicting depth", sep = "")
        if(nrow(deppoi)<= 10000){
          cat(" ", sep = "")
          dept <- as.numeric(predict(SplineD, deppoi[,c("LON","LAT")]))
          dep_v <- as.data.frame(cbind(deppoi[,"rowid"], deppoi[,"I_NCEE"], dept))
          sqldf("insert into p_depth select * from `dep_v`", dbname = the_db)
          rm(dept, dep_v)
          gc()
        }else{
          nPin <- ceiling(nrow(deppoi)/10000)
          for(pi in 1:nPin)
          {
            cat(".", sep = "")
            r1 <- 10000*(pi-1)+1
            r2 <- min(nrow(deppoi),r1+10000-1)
            dept <- as.numeric(predict(SplineD, deppoi[r1:r2,c("LON","LAT")]))
            dep_v <- as.data.frame(cbind(deppoi[r1:r2,"rowid"], deppoi[r1:r2,"I_NCEE"], dept))
            sqldf("insert into p_depth select * from `dep_v`", dbname = the_db)
            rm(dept, dep_v)
            gc()
          }            
        }
        cat(" - Completed!     -\n", sep = "")
        rm(SplineD)
        gc()
      }else{
        xmin_2 <- xmin+((xmax-xmin)/2)
        ymin_2 <- ymin+((ymax-ymin)/2)
        cat("\n   -     Splitting block...     -\n", sep = "")
        recu_dep(xmin, xmin_2, ymin, ymin_2, resolut = resolut, the_db)
        recu_dep(xmin_2, xmax, ymin, ymin_2, resolut = resolut, the_db)
        recu_dep(xmin, xmin_2, ymin_2, ymax, resolut = resolut, the_db)
        recu_dep(xmin_2, xmax, ymin_2, ymax, resolut = resolut, the_db)
      }
    }
  } else {
    cat("\n\n   -     Error! Bad Database File      -\n", sep = "")
  }
}

recu_dep_RDS <- function(bat_all, xmin, xmax, ymin, ymax, the_db = "", max_siz = 0.5, the_bbo)
{
  if(the_db != "")
  {
    
    co_ce <- fn$sqldf("select count(*) from intrp where LON >= `xmin` and LON <= `xmax` and LAT >= `ymin` and LAT <= `ymax`", dbname = the_db)
    
    if(co_ce[1,1] == 0)
    {
      cat("\n  -  Skipped block: x(", xmin, ",",xmax, ")*y(",ymin,",",ymax,")  -\n", sep = "")
    }else{
      xrange = c(xmin, xmax)
      yrange = c(ymin, ymax)
      l_x <- xmax - xmin
      l_y <- ymax - ymin
      if(l_x <= max_siz | l_y <= max_siz)
      {
        cat("\n  -  New valid block", sep = "")
        
        deppoi <- fn$sqldf("select ROWID, * from intrp where LON >= `xmin` and LON <= `xmax` and LAT >= `ymin` and LAT <= `ymax`", dbname = the_db)
        
        cat(" with ", nrow(deppoi), " points", sep = "")
        
        cur_rows <- which(as.numeric(rownames(bat_all)) >= xmin-0.1 & as.numeric(rownames(bat_all)) <= xmax+0.1)
        cur_cols <- which(as.numeric(colnames(bat_all)) >= ymin-0.1 & as.numeric(colnames(bat_all)) <= ymax+0.1)
        
        if(length(cur_rows) > 1 & length(cur_cols) > 1){
          
          # cat("\n rows: ", length(cur_rows), " - cols:", length(cur_cols), "\n", sep = "")
          
          bat_blo <- bat_all[cur_rows, cur_cols]
          
          xlon <- rep(as.numeric(rownames(bat_blo)),length(as.numeric(colnames(bat_blo))))
          ylat <- rep(as.numeric(colnames(bat_blo)),each=length(as.numeric(rownames(bat_blo))))
          zdep <- as.numeric(bat_blo)
#           
#           cat("\n xlon: ", xlon, "\n\n xlat: ", ylat, "\n\n zdep: ", zdep, "\n\n", sep = " ")
#           
          ##########
          blues<-c("lightsteelblue4","lightsteelblue3","lightsteelblue2","lightsteelblue1")
          ba_bl <- as.bathy(cbind(xlon, ylat, zdep))
          par(mar = c(1,1,1,1))
          plot(ba_bl,image=TRUE,land=TRUE,lwd=0.1,bpal=list(c(0,max(zdep),"grey"),c(min(zdep),0,blues)))
          plot(ba_bl,deep=0,shallow=0,step=0,lwd=0.4,add=TRUE)
          ##########
          
          #         plot(as.bathy(cbind(xlon, ylat, zdep)), image = T)
          
          points(deppoi[,"LON"], deppoi[,"LAT"], pch = 20, cex = 0.6, col = "firebrick")
          
          cat("  -  Calculating Spline...", sep = "")
          SplineD <- o_Tps(cbind(xlon, ylat), zdep, lon.lat=TRUE)
          #         cat(class(SplineD), "\n")
          rm(bat_blo, zdep, xlon, ylat)
          
          cat(" Predicting depth...", sep = "")
          if(nrow(deppoi)<= 10000){
            dept <- as.numeric(predict(SplineD, deppoi[,c("LON","LAT")]))
            dep_v <- as.data.frame(cbind(deppoi[,"rowid"], deppoi[,"I_NCEE"], dept))
            sqldf("insert into p_depth select * from `dep_v`", dbname = the_db)
            rm(dept, dep_v)
            gc()
          }else{
            nPin <- ceiling(nrow(deppoi)/10000)
            for(pi in 1:nPin)
            {
              cat(".", sep = "")
              r1 <- 10000*(pi-1)+1
              r2 <- min(nrow(deppoi),r1+10000-1)
              dept <- as.numeric(predict(SplineD, deppoi[r1:r2,c("LON","LAT")]))
              dep_v <- as.data.frame(cbind(deppoi[r1:r2,"rowid"], deppoi[r1:r2,"I_NCEE"], dept))
              sqldf("insert into p_depth select * from `dep_v`", dbname = the_db)
              rm(dept, dep_v)
              gc()
            }            
          }
          cat(" - Completed!  -\n", sep = "")
          map("world", xlim = the_bbo[2:1], ylim = the_bbo[4:3], col="honeydew3",bg="lightsteelblue1", fill = T)
          map.axes()
          
          xmin_2 <- xmin+((xmax-xmin)/2)
          abline(v = xmin_2, col = "firebrick")
          ymin_2 <- ymin+((ymax-ymin)/2)
          abline(h = ymin_2, col = "firebrick")
          
          rect(xmin, ymin, xmin_2, ymin_2, border = "firebrick")
          rect(xmin_2, ymin, xmax, ymin_2, border = "firebrick")
          rect(xmin, ymin_2, xmin_2, ymax, border = "firebrick")
          rect(xmin_2, ymin_2, xmax, ymax, border = "firebrick")
          
          rm(SplineD)
          gc()
        }else{
          cat(" outside downloaded bathymetry  -\n", sep = "")
        }
      }else{
        
        map("world", xlim = the_bbo[2:1], ylim = the_bbo[4:3], col="honeydew3",bg="lightsteelblue1", fill = T)
        map.axes()
        
        title("\n  -  Splitting Block...")
        
        xmin_2 <- xmin+((xmax-xmin)/2)
        abline(v = xmin_2, col = "firebrick")
        ymin_2 <- ymin+((ymax-ymin)/2)
        abline(h = ymin_2, col = "firebrick")
        
        rect(xmin, ymin, xmin_2, ymin_2, border = "firebrick")
        rect(xmin_2, ymin, xmax, ymin_2, border = "firebrick")
        rect(xmin, ymin_2, xmin_2, ymax, border = "firebrick")
        rect(xmin_2, ymin_2, xmax, ymax, border = "firebrick")
        
        recu_dep_RDS(bat_all, xmin, xmin_2, ymin, ymin_2, the_db, max_siz, the_bbo)
        recu_dep_RDS(bat_all, xmin_2, xmax, ymin, ymin_2, the_db, max_siz, the_bbo)
        recu_dep_RDS(bat_all, xmin, xmin_2, ymin_2, ymax, the_db, max_siz, the_bbo)
        recu_dep_RDS(bat_all, xmin_2, xmax, ymin_2, ymax, the_db, max_siz, the_bbo)
      }
    }
  } else {
    cat("\n\n   -     Error! Bad Database File      -\n", sep = "")
  }
}

#' Assign Area - Internal Function
#'  
#' 
#' The \code{Assign_Area} is the internal function that implements the
#'  Assign Area routine.
#' 
#' This function,  with a VMS DB Track and a Sea Areas Shape File,
#'  (see \code{\link{gui_vms_db_are}}),
#'  finds the Sea Area that contain the VMS DB Track.
#'   
#' 
#' @return This function does not return a value. 
#' 
#' @param evnt The VMS Track Data
#' @param box The Sea Areas Shape File Box
#' 
#' @usage Assign_Area(evnt, box)
#'
#'
#'@references free text reference Pointers to the literature related to this object.
#'@seealso \code{\link{gui_vms_db_are}}
#' @name Assign_Area

Assign_Area = function(evnt, box){  
  Area <- max(findPolys(as.EventData(data.frame(EID = 1, X = mean(evnt[,1]), Y = mean(evnt[,2])), projection="LL"), box)[,2])
  if(length(Area) == 0) Area <- NA
  return(Area)
}



merge_source <- function(data_source1, data_source2, rnd_level, minover){
  
  #Inspect sources
  uS1 <- unique(data_source1[,1])
  nuS1 <- length(uS1)
  uS2 <- unique(data_source2[,1])
  nuS2 <- length(uS2)
  
  #   #Set parameters
  #   npmin <- 30
  #   minover <- 30
  #   rnd_level <- 3
  
  #Select the sources with the highest number of vessels
  if(nuS1 < nuS2){
    main_source <- data_source1
    secondary_source <- data_source2
  }else{
    main_source <- data_source2
    secondary_source <- data_source1
  }
  
  #Compute basic statistics
  uS1 <- unique(main_source[,1])
  nuS1 <- length(uS1)
  uS2 <- unique(secondary_source[,1])
  nuS2 <- length(uS2)
  
  matd <- matrix(data = Inf, nrow = nuS1, ncol = nuS2)
  rownames(matd) <- uS1
  colnames(matd) <- uS2
  iter <- 0
  
  for(i in 1:nuS1){
    block_s1 <- main_source[which(main_source[,1]== uS1[i]),] 
    #Spatial Overlap
    spat_data_source <- secondary_source[which((secondary_source$LON <= max(block_s1$LON))&
                                                 (secondary_source$LON >= min(block_s1$LON))&
                                                 (secondary_source$LAT <= max(block_s1$LAT))&
                                                 (secondary_source$LAT >= min(block_s1$LAT))),]
    candidate_ID <- unique(spat_data_source$I_NCEE)
    nuC <- length(candidate_ID)
    
    for(j in 1:nuC){
      block_s2 <- spat_data_source[which(spat_data_source[,1] == candidate_ID[j]),] 
      
      #Semisincronicity
      overtimes_ss <- intersect(round(block_s1$DATE,rnd_level),
                                round(block_s2$DATE,rnd_level)) 
      if(length(overtimes_ss) > minover){
        block_s1 <- block_s1[order(round(block_s1$DATE,rnd_level)),]
        block_s2 <- block_s2[order(round(block_s2$DATE,rnd_level)),]
        sub_block_s1 <- block_s1[which(round(block_s1$DATE,rnd_level) %in% overtimes_ss),]
        sub_block_s2 <- block_s2[which(round(block_s2$DATE,rnd_level) %in% overtimes_ss),] 
        if(length(which(duplicated(round(sub_block_s1$DATE,rnd_level))==TRUE))>0)
          sub_block_s1 <- sub_block_s1[-which(duplicated(round(sub_block_s1$DATE,rnd_level))==TRUE),]
        if(length(which(duplicated(round(sub_block_s2$DATE,rnd_level))==TRUE))>0)
          sub_block_s2 <- sub_block_s2[-which(duplicated(round(sub_block_s2$DATE,rnd_level))==TRUE),]    
        inter_blocks_dists <- gmt::geodist(sub_block_s1[,c("LAT")],
                                           sub_block_s1[,c("LON")],
                                           sub_block_s2[,c("LAT")],
                                           sub_block_s2[,c("LON")],units="km")
        matd[which(uS1 == uS1[i]),which(uS2 == candidate_ID[j])] <- median(inter_blocks_dists)
      }
    }
    iter <- iter + 1
    cat(iter," of ",nuS1," ",nuC," candidates found","\n")
  }
  return(matd)
}



o_Tps <- function(x, Y, m = NULL, p = NULL, scale.type = "range", 
                  lon.lat = FALSE, miles = TRUE, ...) {
  x <- as.matrix(x)
  d <- ncol(x)
  if (is.null(p)) {
    if (is.null(m)) {
      m <- max(c(2, ceiling(d/2 + 0.1)))
    }
    p <- (2 * m - d)
    if (p <= 0) {
      stop(" m is too small  you must have 2*m -d >0")
    }
  }
  Tpscall <- match.call()
  if (!lon.lat) {
    Tpscall$cov.function <- "Thin plate spline radial basis functions (Rad.cov) "
    Krig(x, Y, cov.function = Rad.cov, m = m, scale.type = scale.type, 
         p = p, GCV = TRUE, ...)
  }
  else {
    # use different coding of the radial basis fucntions to use with great circle distance.
    Tpscall$cov.function <- "Thin plate spline radial basis functions (RadialBasis.cov) using great circle distance "
    Krig(x, Y, cov.function = stationary.cov, m = m, scale.type = scale.type, 
         GCV = TRUE, cov.args = list(Covariance = "RadialBasis", 
                                     M = m, dimension = 2, Distance = "rdist.earth", 
                                     Dist.args = list(miles = miles)), ...)
  }
}



#' Effort Count - Internal Function
#'  
#' 
#' The \code{CountMap} is the internal function that implements the
#'  Effort Count routine.
#' 
#' This function,  with a VMS DB Track and a Sea Areas Shape File,
#'  (see \code{\link{gui_out_grid}}),
#'  computes the Effort Count Vector.
#'   
#' 
#' @return This function does not return a value. 
#' 
#' @param xy The VMS Fishing Point Data
#' @param GridPS The Sea Area Grid File
#' 
#' @usage CountMap(xy, GridPS)
#'
#'
#' @references free text reference Pointers to the literature related to this object.
#' @seealso \code{\link{gui_out_grid}}
#' @name CountMap

CountMap = function(xy, GridPS){
  PP=xy[,c(1:2)]
  GridCount = matrix(0,length(unique(GridPS$PID)),2)
  colnames(GridCount) = c("cellID","Count")
  if(nrow(PP)<= 100000){
    Poi=matrix(0,nrow(PP),3)
    colnames(Poi)=c("EID","X","Y")
    Poi[,1]=c(1:nrow(Poi))
    Poi[,2]=PP[,1]
    Poi[,3]=PP[,2]
    idPolys = findPolys(Poi, GridPS)
    idTable = table(idPolys[,2])
    GridCount[,1] = 1:length(unique(GridPS$PID))
    GridCount[as.numeric(names(idTable)),2] = as.numeric(idTable)
  }else{
    nPP <- ceiling(nrow(PP)/100000)
    #     GridCount = matrix(0,length(unique(GridPS$PID)),2) 
    for(pi in 1:nPP){
      cat(".", sep = "")
      r1 <- 100000*(pi-1)+1
      r2 <- min(nrow(PP),r1+100000-1)
      Poi=matrix(0,r2-r1+1,3)
      colnames(Poi)=c("EID","X","Y")
      Poi[,1]=c(1:nrow(Poi))
      Poi[,2]=PP[r1:r2,1]
      Poi[,3]=PP[r1:r2,2]
      #GridPS = SpatialPolygons2PolySet(GSA)
      idPolys = findPolys(Poi, GridPS) #Supporta fino a 100.000 punti
      idTable = table(idPolys[,2])
      GridCount_part = matrix(0,length(unique(GridPS$PID)),2)
      colnames(GridCount_part) = c("cellID","Count")
      GridCount_part[,1] = 1:length(unique(GridPS$PID))
      GridCount_part[as.numeric(names(idTable)),2] = as.numeric(idTable)
      GridCount[,2]=GridCount[,2]+GridCount_part[,2]
    }
  }
  return(GridCount[,2])
}
